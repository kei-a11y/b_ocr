import os, io, sys,re, cv2, pytesseract
from pathlib import Path
from PIL import Image, ImageOps, ImageEnhance
import numpy as np
import pandas as pd
from openpyxl import load_workbook
from django.conf import settings
import os


pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# --- 外部ライブラリ読み込み（無ければ適宜メッセージ） ---
try:
    import fitz  # PyMuPDF
except Exception:
    raise RuntimeError("PyMuPDF が必要です。pip install pymupdf を実行してください。")

try:
    import cv2
    _have_cv2 = True
except Exception:
    _have_cv2 = False
    print("WARN: OpenCV が見つかりません。桁分割は簡易モードになります。pip install opencv-python を推奨します.")

try:
    import tensorflow as tf
    _have_tf = True
except Exception:
    _have_tf = False
    print("WARN: tensorflow が見つかりません。モデル推論は実行されません。pip install tensorflow を実行してください.")

# ------------------ ユーザ設定エリア ------------------
BASE_DIR = Path(__file__).parent # スクリプトのあるディレクトリを取得
PDF_PATH = BASE_DIR / "@pdf" / "kk.pdf"
PAGE_INDEX = 0
DEBUG_DIR = "debug_crops"
DPI = 200

# 正規化座標 (ユーザが調整済みの値をそのまま使用)　★左端起点x0,上端起点y0,左端終点x1,上端終点y1
BOX_RECIPIENT = (0.155, 0.100, 0.305, 0.135)
BOX_NAME = (0.465, 0.100, 0.625, 0.1175)
BOX_SERVICE   = (0.1425, 0.2210, 0.2155, 0.8435)
BOX_STARTS    = (0.2165, 0.2210, 0.3115, 0.8435)
BOX_ENDS      = (0.3135, 0.2210, 0.4085, 0.8435)
BOX_WAYgo     = (0.4100, 0.2210, 0.4340, 0.8435)
BOX_WAYback   = (0.4340, 0.2210, 0.4580, 0.8435)
BOX_MEAL      = (0.5545, 0.2210, 0.5905, 0.8435)
BOX_MEDIC     = (0.5915, 0.2210, 0.6265, 0.8435)
BOX_TRIAL     = (0.6275, 0.2210, 0.6625, 0.8435)
BOX_AREA      = (0.6635, 0.2210, 0.6995, 0.8435)

NUM_ROWS = 31
MODEL_CANDIDATES = ["best_model.h5", "mnist_model.h5"]
# -------------------------------------------------------

def ensure_dir(p):
    Path(p).mkdir(parents=True, exist_ok=True)

#--- PDFの指定ページを画像（PIL形式）に変換する関数
def pdf_page_to_pil(pdf_path, page_num=0, dpi=200):
    doc = fitz.open(pdf_path)
    if page_num < 0 or page_num >= doc.page_count:
        raise ValueError("page_num out of range")
    page = doc.load_page(page_num)
    mat = fitz.Matrix(dpi / 72, dpi / 72)
    pix = page.get_pixmap(matrix=mat) #-----------------PDFページをピクセルマップに変換
    img = Image.open(io.BytesIO(pix.tobytes("png"))) #--PIL画像に変換
    return img.convert("RGB")


#--- 画像を指定された範囲で切り取るための関数
def crop_norm(img, box):#--------------------- img=PILのImageオブジェクト、box=正規化された座標（main内で代入）
    w, h = img.size
    x0 = int(box[0] * w)
    y0 = int(box[1] * h)
    x1 = int(box[2] * w)
    y1 = int(box[3] * h)
    return img.crop((x0, y0, x1, y1)) #--- PILのcrop()メソッドを使って指定範囲を切り取る


#---31日だから31分割するコード（罫線を検出できなかったときのためのフォールバック）
def split_vertical(box_img, n_rows):
    w, h = box_img.size
    row_h = h / n_rows
    crops = []
    for i in range(n_rows):
        y0 = int(i * row_h)
        y1 = int((i + 1) * row_h)
        crops.append(box_img.crop((0, y0, w, y1)))
    return crops


#---罫線を検出して区切るコード　#---エクセルの罫線は太くしないと認識しない！
def split_rows_by_lines(img, debug_name=""):
    gray = np.array(img.convert("L"))
    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # 横線を強調（横方向に長い形状を抽出）
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))
    horizontal = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel, iterations=2)

    # 輪郭から罫線候補を検出
    contours, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    y_positions = []
    for c in contours:
        x, y, w, h = cv2.boundingRect(c)
        if w > img.width * 0.5:  # ページ幅の半分以上なら罫線とみなす
            y_positions.append(y)

    if not y_positions:
        print("Warning: 罫線が検出できませんでした")
        return [img]

    # y座標をソート
    y_positions = sorted(y_positions)

    # 隣り合う罫線の間を切り出し
    rows = []
    for i in range(len(y_positions) - 1):
        y0, y1 = y_positions[i], y_positions[i+1]
        row_img = img.crop((0, y0, img.width, y1))
        if debug_name:
            ensure_dir("mid")
            row_img.save(Path("mid") / f"{debug_name}_row_{i+1}.png")
        rows.append(row_img)

    return rows


#---受給者証番号をOCR + fallbackで認識
def predict_recipient_number(img, model, debug_name="recipient"):

    # --- Step 1: Tesseract OCR (数字限定) ---
    config = "--psm 7 -c tessedit_char_whitelist=0123456789"
    text = pytesseract.image_to_string(img, config=config).strip()
    digits = re.sub(r"\D", "", text)  # 数字以外削除

    # --- Step 2: Tesseractの結果が10桁なら即採用 ---
    if len(digits) == 10:
        return digits

    # --- Step 3: fallback: 手書きモデル ---
    if model is not None:
        val = predict_digits_with_model(model, img, debug_name)
        # → 桁数はとりあえず返す（Excelに痕跡を残す）
        if val:
            return val

    # --- Step 4: どちらも失敗 ---
    return digits  # もしTesseractが9桁とかならそのまま残す


#---受給者名（カナ）をOCRで認識
def predict_name(img, model=None, debug_name="name"):
    # --- 余白をトリミング ---
    w, h = img.size
    margin_x = int(w * 0.1)   # 左右10%カット
    margin_y = int(h * 0.05)   # 上下0.5%カット
    cropped = img.crop((margin_x, margin_y, w - margin_x, h - margin_y))

    # --- リサイズ（拡大してOCR精度を上げる） ---
    scale = 3
    resized = cropped.resize((cropped.width * scale, cropped.height * scale), Image.Resampling.LANCZOS)

    # --- コントラスト強調 + グレースケール + 二値化 ---
    gray = resized.convert("L")
    enhancer = ImageEnhance.Contrast(gray)
    gray = enhancer.enhance(3.0)
    bw = gray.point(lambda x: 0 if x < 160 else 255, '1')

    if debug_name:
        ensure_dir("mid")
        bw.save(Path("mid") / f"{debug_name}_preprocessed.png")

    # --- OCR (カタカナ限定, 複数文字に強いpsm=6) ---
    config = "--psm 6"
    try:
        #--- lang="jpn"で日本語データを使うということ
        text = pytesseract.image_to_string(bw, "jpn", config=config).strip()
    except Exception as e:
        print("Tesseract error (Name OCR):", e)
        return ""

    text = re.sub(r"[^ァ-ヴー]", "", text)

    return text


#--- 四隅のランドマーク(■)を基準に射影変換
def align_using_corner_marks(scanned_img, dpi, template_pdf_path):
    
    # テンプレート画像化
    template_img_path = "template_image.png"
    if not Path(template_img_path).exists():
        tmp_img = pdf_page_to_pil(template_pdf_path, 0, dpi)
        tmp_img.save(template_img_path)
    template_img = cv2.cvtColor(np.array(Image.open(template_img_path)), cv2.COLOR_RGB2BGR)
    
    def find_marks(img_bgr, debug=False):
        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        
        # より強力な前処理
        # 1. ガウシアンフィルタでノイズ除去
        gray = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # 2. 適応的閾値処理（照明ムラに強い）
        bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        
        # 3. より大きなカーネルでCLOSE処理
        kernel_close = np.ones((20, 20), np.uint8)
        bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel_close)
        
        # 4. OPEN処理でノイズ除去
        kernel_open = np.ones((5, 5), np.uint8)
        bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel_open)
        
        if debug:
            cv2.imwrite("debug_binary.png", bw)
        
        # 輪郭取得
        contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        h, w = bw.shape
        marks = []
        
        # より柔軟なマージン設定（斜めの画像に対応）
        margin_x = w * 0.15  # 横15%
        margin_y = h * 0.15  # 縦15%
        
        mark_candidates = []
        
        for c in contours:
            area = cv2.contourArea(c)
            
            # 面積フィルタを緩和
            if area < 30 or area > w * h * 0.01:  # 最小30ピクセル、最大画像の1%
                continue
            
            # 輪郭の近似
            epsilon = 0.02 * cv2.arcLength(c, True)
            approx = cv2.approxPolyDP(c, epsilon, True)
            
            x, y, ww, hh = cv2.boundingRect(c)
            cx, cy = x + ww / 2, y + hh / 2
            
            # アスペクト比チェック（正方形に近いものを優先）
            aspect_ratio = ww / hh if hh > 0 else 0
            if not (0.5 <= aspect_ratio <= 2.0):
                continue
            
            # 四隅付近にあるかチェック（より柔軟に）
            is_corner = False
            corner_type = None
            
            # 左上
            if cx < margin_x and cy < margin_y:
                is_corner = True
                corner_type = "top_left"
            # 右上
            elif cx > w - margin_x and cy < margin_y:
                is_corner = True
                corner_type = "top_right"
            # 左下
            elif cx < margin_x and cy > h - margin_y:
                is_corner = True
                corner_type = "bottom_left"
            # 右下
            elif cx > w - margin_x and cy > h - margin_y:
                is_corner = True
                corner_type = "bottom_right"
            
            if is_corner:
                # 品質スコア計算（面積、アスペクト比、輪郭の複雑さを考慮）
                quality_score = area * (1 / abs(1 - aspect_ratio) if aspect_ratio != 1 else 1) * (1 / len(approx) if len(approx) > 0 else 0)
                
                mark_candidates.append({
                    'center': (cx, cy),
                    'corner_type': corner_type,
                    'area': area,
                    'quality': quality_score,
                    'aspect_ratio': aspect_ratio
                })
        
        if debug:
            print(f"マーク候補数: {len(mark_candidates)}")
            for i, candidate in enumerate(mark_candidates):
                print(f"候補{i}: {candidate['corner_type']}, 中心({candidate['center'][0]:.1f}, {candidate['center'][1]:.1f}), 面積:{candidate['area']}, 品質:{candidate['quality']:.2f}")
        
        # 各コーナーから最も品質の高い候補を選択
        corner_types = ["top_left", "top_right", "bottom_left", "bottom_right"]
        selected_marks = []
        
        for corner in corner_types:
            candidates = [c for c in mark_candidates if c['corner_type'] == corner]
            if candidates:
                # 品質スコアで並び替えて最良のものを選択
                best = max(candidates, key=lambda x: x['quality'])
                selected_marks.append(best['center'])
        
        if len(selected_marks) == 4:
            # 順序を統一（左上、右上、右下、左下の順）
            return selected_marks
        
        # 4つ見つからない場合は、距離ベースでの補完を試行
        if len(selected_marks) >= 2:
            print(f"Warning: {len(selected_marks)}個のマークのみ検出。距離ベース補完を試行中...")
            # ここで距離や角度から欠けているマークを推定する処理を追加可能
        
        return []
   
    # スキャン画像のマーク検出（デバッグモード有効）
    scanned_bgr = cv2.cvtColor(np.array(scanned_img), cv2.COLOR_RGB2BGR)
    src_pts = find_marks(scanned_bgr, debug=True)
    
    # テンプレート画像のマーク検出
    dst_pts = find_marks(template_img, debug=False)
    
    if len(src_pts) != 4 or len(dst_pts) != 4:
        print(f"Warning: 四隅マークの検出に失敗しました")
        print(f"スキャン画像: {len(src_pts)}個検出")
        print(f"テンプレート: {len(dst_pts)}個検出")
        print("（補正なし）")
        return scanned_img
    
    print("四隅マーク検出成功！射影変換を実行中...")
    
    # numpy配列に変換
    src_pts = np.float32(src_pts)
    dst_pts = np.float32(dst_pts)
    
    # 射影変換行列計算
    M = cv2.getPerspectiveTransform(src_pts, dst_pts)
    
    # 射影変換実行
    h, w = template_img.shape[:2]
    warped = cv2.warpPerspective(np.array(scanned_img), M, (w, h))
    
    return Image.fromarray(warped)



def save_results_to_excel(rows, recipient_digits, name_digits, output_base="output",
                          template_xlsx_path=os.path.join(settings.BASE_DIR, "static_files", "documents", "template.xlsx"),
                          seq_no=1): # ★変更===template_xlsx_path=os.path.join(settings.BASE_DIR,とする
    # 既存の帳票テンプレートを読み込む
    wb = load_workbook(template_xlsx_path) # ★変更===template_xlsx_pathとした
    ws = wb.active

    # === 固定セル ===
    ws["J5"]  = recipient_digits   # 受給者証番号
    ws["AK5"] = name_digits        # 受給者名（カナ）

    # === 行データ ===
    for idx, row in enumerate(rows, start=13):
        ws[f"J{idx}"]  = row.get("Service", "")
        ws[f"P{idx}"]  = row.get("Start", "")
        ws[f"X{idx}"]  = row.get("End", "")
        ws[f"AF{idx}"]  = row.get("Way_go", "")
        ws[f"AH{idx}"]  = row.get("Way_back", "")
        ws[f"AO{idx}"] = row.get("Meal", "")
        ws[f"AR{idx}"] = row.get("Medic", "")
        ws[f"AU{idx}"] = row.get("Trial", "")
        ws[f"AX{idx}"] = row.get("Area", "")

    # === ファイル名決定ロジック（修正版） ===
    recipient = (recipient_digits or "").strip()
    name = (name_digits or "").strip()

    if recipient and name:
        filename = f"{recipient}{name}.xlsx"
    elif not recipient and name:
        filename = f"{seq_no}受給者証番号入力なし{name}.xlsx"
    elif recipient and not name:
        filename = f"{recipient}.xlsx"
    else:
        filename = f"{seq_no}受給者証番号入力なし.xlsx"

# ★変更=== output_path について、output_baseがディレクトリパスの場合はファイル名を結合、そうでなければそのまま使用 ===
    if os.path.isdir(output_base) or output_base.endswith('/') or output_base.endswith('\\'):
        output_path = os.path.join(output_base, filename)
    else:
        # output_baseが既にファイル名を含んでいる場合（従来の使い方との互換性維持）
        output_path = f"{output_base}.xlsx"

    # === 保存 ===
    wb.save(output_path)
    print("Excelに書き込みました ->", output_path)

# ★変更=== ↓新規追加 
    # 作成されたファイルのパスを返す
    return output_path


def remove_lines(img, debug=True, debug_name="debug"):
    """
    入力画像から横線・縦線を検出して白塗りした画像を返す。
    - 横線: 幅90%以上、細長い水平線
    - 縦線: 高さ90%以上、細長い垂直線
    - debug=Trueで中間結果を保存
    """
    gray = img.convert('L')
    gray_np = np.array(gray)

    # 2値化（強めの閾値）
    _, bin_img = cv2.threshold(gray_np, 180, 255, cv2.THRESH_BINARY_INV)

    img_no_lines = gray_np.copy()
    height, width = bin_img.shape

    # === 横線検出 ===
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (max(3, width // 2), 1))
    detected = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, horizontal_kernel)
    cnts, _ = cv2.findContours(detected, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for c in cnts:
        x, y, w_rect, h_rect = cv2.boundingRect(c)
        aspect_ratio = w_rect / (h_rect + 1e-5)
        if aspect_ratio > 10 and w_rect > width * 0.85:
            cv2.rectangle(img_no_lines, (x, y), (x+w_rect, y+h_rect), 255, -1)

    # === 縦線検出 ===
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, max(3, height // 2)))
    detected = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, vertical_kernel)
    cnts, _ = cv2.findContours(detected, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for c in cnts:
        x, y, w_rect, h_rect = cv2.boundingRect(c)
        aspect_ratio = h_rect / (w_rect + 1e-5)
        if aspect_ratio > 10 and h_rect > height * 0.85:
            cv2.rectangle(img_no_lines, (x, y), (x+w_rect, y+h_rect), 255, -1)

    img_result = Image.fromarray(img_no_lines)

    # === デバッグ用保存 ===
    if debug:
        os.makedirs("remove_line", exist_ok=True)
        Image.fromarray(bin_img).save(f"remove_line/{debug_name}_bin.png")
        img_result.save(f"remove_line/{debug_name}_no_lines.png")

    return img_result


def is_blank_image(img, mode="soft", debug=False, debug_name="debug"):
    """
    空欄判定:
      - remove_lines() で罫線を削除
      - mode="soft": 枠を軽く避ける
      - mode="hard": より厳しく中央寄せ
      - 黒ピクセル割合が閾値以下なら空白
    """
    # --- 罫線削除 ---
    img_no_lines = remove_lines(img, debug=debug, debug_name=debug_name)

    # --- クロップ＆閾値設定 ---
    w, h = img_no_lines.size
    if mode == "soft":
        threshold = 0.04
        img_cropped = img_no_lines.crop((int(w*0.015), int(h*0.025),
                                         int(w*0.985), int(h*0.985)))
    else:
        threshold = 0.015
        img_cropped = img_no_lines.crop((int(w*0.035), int(h*0.055),
                                         int(w*0.975), int(h*0.955)))

    # --- 二値化（完全白黒） ---
    bw = img_cropped.point(lambda x: 0 if x < 150 else 255, '1')

    # --- 黒ピクセル割合計算 ---
    black_pixels = bw.histogram()[0]
    total_pixels = bw.width * bw.height
    black_ratio = black_pixels / total_pixels

    # --- デバッグ出力 ---
    if debug:
        os.makedirs("remove_line", exist_ok=True)
        img_no_lines.save(f"remove_line/{debug_name}_no_lines.png")
        bw.save(f"remove_line/{debug_name}_binary.png")
        print(f"[DEBUG] 黒比率: {black_ratio:.4f} / 閾値: {threshold}")

    return black_ratio <= threshold


# -----モデル入力用に 28x28 -> (1,28,28,1) の numpy 配列にする
def preprocess_for_model(pil_img, invert=True, debug_name="", idx=None, seq_no=None):
    img = pil_img.convert("L")
    if invert:
        img = ImageOps.invert(img)  # postproc の画像を黒白反転させる

    # パディングして正方形化（余白に黒背景を追加）
    w, h = img.size
    side = max(w, h)
    padded = Image.new("L", (side, side), 0)  # 黒背景
    padded.paste(img, ((side - w) // 2, (side - h) // 2))

    img = padded.resize((28, 28), Image.Resampling.LANCZOS)

    # デバッグ保存
    if debug_name and idx is not None:
        ensure_dir("debug_inputs")
        suffix = f"_p{seq_no}" if seq_no is not None else ""
        img.save(f"debug_inputs/{debug_name}{suffix}_digit{idx}.png")

    arr = np.array(img).astype("float32") / 255.0
    arr = arr.reshape(1, 28, 28, 1)
    return arr


# -----MODEL_CANDIDATES = ["best_model.h5", "mnist_model.h5"]の読み込み
# -----main内で、model = load_model_if_exists()と宣言
def load_model_if_exists():
    if not _have_tf:
        return None
    for p in MODEL_CANDIDATES:
        if Path(p).exists():
            try:
                print("Loading model:", p)
                model = tf.keras.models.load_model(p)
                print("Loaded model:", p)
                return model
            except Exception as e:
                print("Failed to load model", p, ":", e)
    print("No model found among:", MODEL_CANDIDATES)
    return None


#--- HHMM 正規化（例: "9"→"0900", "10"→"1000", "900"→"0900"）
def normalize_hhmm_digits(digits: str) -> str:
    if not digits:
        return ""
    digits = re.sub(r"\D", "", digits)
    if len(digits) >= 4:
        return digits[:4]
    if len(digits) == 3:
        return digits.zfill(4)  # "900" -> "0900"
    if len(digits) == 2:
        if int(digits) < 24:
            return digits + "00"       # "10" -> "1000"
        else:
            return "0" + digits + "0"  # "90" -> "0900"
    if len(digits) == 1:
        return digits.zfill(2) + "00"  # "9" -> "0900"
    return ""


def remove_colon_and_noise(pil_img, debug_name=""):
    # -----改良版: 小さな '0' を消さないために輪郭判定を賢くする。
    ensure_dir("mid")
    img_gray = pil_img.convert("L")
    if debug_name:
        img_gray.save(Path("mid") / f"{debug_name}_00_original.png")

    arr = np.array(img_gray)

    #--- Otsu の閾値値を取得してマージンを使う
    #--- OpenCV のcv2.threshold：大津の手法 (Otsu's method)
    #---「画像のヒストグラム（二値化前の明るさ分布）を解析して、クラス内分散を最小にする閾値」を自動的に決める手法
    #--- つまり、明るい背景と暗い文字があるとき、それらを最もきれいに分ける閾値（0〜255の数値）を自動で計算してくれる
    otsu_val, _ = cv2.threshold(arr, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    thr = max(0, int(otsu_val) - 1) # margin を調整（初期値-1 ± 値を試してください）
    _, bw = cv2.threshold(arr, thr, 255, cv2.THRESH_BINARY_INV)
    if debug_name:
        Image.fromarray(bw).save(Path("mid") / f"{debug_name}_01_bw.png")

    # 小さなノイズ除去（開閉で軽く掃く）
    bw_open = cv2.morphologyEx(bw, cv2.MORPH_OPEN, np.ones((2,2), np.uint8))
    if debug_name:
        Image.fromarray(bw_open).save(Path("mid") / f"{debug_name}_02_open.png")

    # 輪郭取得（階層情報も）
    contours, hierarchy = cv2.findContours(bw_open.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    h_img, w_img = bw_open.shape
    clean_mask = np.zeros_like(bw_open)

    # 判定用パラメータ（調整可）
    AREA_LARGE = 60       # これ以上はほぼ確実に数字
    AREA_SMALL = 12       # これ以上なら候補にする
    H_RATIO = 0.25        # 高さ比（大）
    H_SMALL_RATIO = 0.10  # 高さ比（小）
    MIN_W_RATIO = 0.03    # 最低幅比（小さいが意味ある幅）

    if hierarchy is None:
        hierarchy = np.array([]).reshape(1,0,4)

    # まず、「保持候補」を集める
    keep_flags = [False] * len(contours)
    for i, c in enumerate(contours):
        area = cv2.contourArea(c)
        x, y, w, h = cv2.boundingRect(c)
        ar = w / float(h + 1e-9)

        keep = False
        # 大きくて高さ比が取れるなら確定
        if area >= AREA_LARGE and h >= h_img * H_RATIO:
            keep = True
        else:
            # 小さめでも縦横比・高さで候補
            if area >= AREA_SMALL and (h >= h_img * H_SMALL_RATIO or w >= w_img * MIN_W_RATIO):
                if 0.15 <= ar <= 6.0:
                    keep = True
        # 親子関係がある場合（穴や内部構造）は保持
        if not keep:
            child_idx = hierarchy[0][i][2] if hierarchy.size else -1
            parent_idx = hierarchy[0][i][3] if hierarchy.size else -1
            if child_idx != -1 or parent_idx != -1:
                keep = True

        keep_flags[i] = keep

    # 描画：保持フラグが True な輪郭を塗る
    for i, c in enumerate(contours):
        if keep_flags[i]:
            cv2.drawContours(clean_mask, [c], -1, 255, thickness=-1)

    if debug_name:
        Image.fromarray(clean_mask).save(Path("mid") / f"{debug_name}_03_mask.png")

    # 子輪郭（穴）を黒で描画して穴を作る（parent/child 情報を利用）
    for i, c in enumerate(contours):
        parent_idx = hierarchy[0][i][3] if hierarchy.size else -1
        if parent_idx != -1:
            # 親が存在するなら穴として残す（親が描かれていれば効果あり）
            cv2.drawContours(clean_mask, [c], -1, 0, thickness=-1)

    if debug_name:
        Image.fromarray(clean_mask).save(Path("mid") / f"{debug_name}_03_mask_after_holes.png")

    # 最終反転（モデルは白背景黒文字想定）
    final_mask = cv2.bitwise_not(clean_mask)
    final_img = Image.fromarray(final_mask)
    if debug_name:
        final_img.save(Path("mid") / f"{debug_name}_04_final.png")

    return final_img


def split_into_digits(img, debug_name=""):
    # -----OpenCVで桁分割（debug_name 指定で mid/ に途中画像を保存）
    if not _have_cv2:
        return [img]

    # コロン除去＋ノイズ処理
    img_clean = remove_colon_and_noise(img, debug_name)

    # === 枠を避けるために少し内側をトリミング ===
    trim_x = int(img_clean.width * 0.04)   # 左右4%カット（調整可）
    trim_y = int(img_clean.height * 0.06)  # 上下6%カット（調整可）
    img_proc = img_clean.crop((
        trim_x,
        trim_y,
        img_clean.width - trim_x,
        img_clean.height - trim_y
    ))
    if debug_name:
        ensure_dir("mid")
        img_proc.save(Path("mid") / f"{debug_name}_trimmed.png")

    # 二値化
    gray = np.array(img_proc.convert("L"))
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # 輪郭抽出
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    MIN_AREA_DIGIT = 30
    MIN_HEIGHT_RATIO = 0.12  # 画像高さの◎%以上

    for c in contours:
        area = cv2.contourArea(c)
        x, y, w, h = cv2.boundingRect(c)
        if area > MIN_AREA_DIGIT and h > img_proc.height * MIN_HEIGHT_RATIO:
            boxes.append(cv2.boundingRect(c))

    if not boxes:
        return [img_proc]

    boxes = sorted(boxes, key=lambda b: b[0])  # 左から右
    digit_imgs = []
    for idx, (x, y, w, h) in enumerate(boxes):
        pad = 2
        x0 = max(0, x - pad)
        y0 = max(0, y - pad)
        x1 = min(img_proc.width, x + w + pad)
        y1 = min(img_proc.height, y + h + pad)
        digit_img = img_proc.crop((x0, y0, x1, y1))
        if not is_blank_image(digit_img, "soft"):#####
            # debug 保存
            if debug_name:
                ensure_dir("mid")
                digit_img.save(Path("mid") / f"{debug_name}_digit_{idx+1}.png")
            digit_imgs.append(digit_img)

    return digit_imgs


def predict_digits_with_model(model, img, debug_name=""):
    if model is None:
        return ""

    # 桁分割（debug_name を渡す）
    imgs = split_into_digits(img, debug_name) # 1830のような時刻画像を1,8,3,0,のように切り出す。

    preds = []
    for idx, im in enumerate(imgs):
        if is_blank_image(im):
            continue
        # debug 保存 (桁ごとの中身を確認したい時)
        if debug_name:
            ensure_dir("mid")
            im.save(Path("mid") / f"{debug_name}_postproc_{idx+1}.png")

        arr = preprocess_for_model(im, invert=True, debug_name=debug_name, idx=idx+1)
        out = model.predict(arr, verbose=0)
        d = str(int(np.argmax(out, axis=1)[0]))
        if d.isdigit():
            preds.append(d)

    result = "".join(preds)
    result = result.replace(":", "").replace("・", "").replace(".", "")

    return result


#--- 開始・終了時刻を OCR → fallback
def ocr_time_with_fallback(pil_img, model=None, debug_name=""):
    # まず罫線を除去
    pil_img = remove_lines(pil_img, debug=False, debug_name=f"{debug_name}_for_ocr")

    text = ""
    try:
        text = pytesseract.image_to_string(
            pil_img,
            config="--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789:："
        ).strip()
    except Exception as e:
        print("Tesseract error:", e)
    digits = re.sub(r"\D", "", text) #-------- 数字だけ抽出（例: "18:30" → "1830"

    #---- Tesseract の結果が3桁or4桁にならないorありえない時間の場合OCR処理をするようにする
    if (len(digits) not in (3, 4) or int(digits) > 2400 or re.search(r"\D", text)) and model is not None:
        #------------------------------------- ↓今度はpredict_digits_with_model関数に投げる
        val = predict_digits_with_model(model, pil_img, debug_name=debug_name)
        return normalize_hhmm_digits(val)
    else:
        norm = normalize_hhmm_digits(digits)#----- tesseractで読取った数字を"900"→"0900" 4桁形式に揃える
        return norm


#--- 開始・終了時刻"以外"を OCR → fallback モデル の2段階で推定する
def ocr_etc_with_fallback(pil_img, model=None, debug_name=""):
    # --- Step1: OCR ---
    text = ""
    try:
        text = pytesseract.image_to_string(
            pil_img,
            config="--psm 7 -c tessedit_char_whitelist=0123456789"
        ).strip()
    except Exception as e:
        print("Tesseract error:", e)

    # --- 数字だけ抽出 ---
    digits = re.sub(r"\D", "", text)

    # --- Step2: fallback ---
    if len(digits) != 1:
        if model is not None:
            val = predict_digits_with_model(model, pil_img, debug_name=debug_name)
            return val
    return digits


# ★変更=== viewsからpredict_from_pdf_B.pyを呼ぶための処理　mainをprocess_pdf_to_excelに変更
from datetime import datetime

def process_pdf_to_excel_with_progress(pdf_path, output_dir="downloads", progress_callback=None):
    """
    プログレスバー対応版のPDF処理関数
    progress_callback: (progress_percentage, message) を受け取るコールバック関数
    """
    def update_progress(progress, message):
        if progress_callback:
            progress_callback(progress, message)
    
    ensure_dir(output_dir)
    update_progress(5, "AIモデルを読み込み中...")
    model = load_model_if_exists()
    
    output_files = []
    update_progress(10, "PDFファイルを解析中...")
    doc = fitz.open(pdf_path)
    total_pages = doc.page_count

    # === ページごとに処理 ===
    for seq_no, page_index in enumerate(range(doc.page_count), start=1):
        base_progress = 15 + (70 * seq_no / total_pages)  # 15%から85%まで
        
        update_progress(base_progress, f"ページ {seq_no}/{total_pages} を処理中...")
        
        page_img = pdf_page_to_pil(pdf_path, page_index, DPI)
        update_progress(base_progress + 5, f"ページ {seq_no}/{total_pages} の画像位置を補正中...")
        
        page_img = align_using_corner_marks(page_img, DPI, 
                        os.path.join(settings.BASE_DIR, "static_files", "documents", "template.pdf"))

        update_progress(base_progress + 10, f"ページ {seq_no}/{total_pages} の受給者情報を読み取り中...")
        
        # 受給者証番号・名前OCR
        recipient_box = crop_norm(page_img, BOX_RECIPIENT)
        recipient_digits = predict_recipient_number(recipient_box, model, debug_name=f"recipient_{seq_no}")
        name_box = crop_norm(page_img, BOX_NAME)
        name_digits = predict_name(name_box, model, debug_name=f"name_{seq_no}")

        update_progress(base_progress + 20, f"ページ {seq_no}/{total_pages} の各項目領域を切り出し中...")
        
        # 列ごとの領域切り出し
        service_box  = crop_norm(page_img, BOX_SERVICE)
        starts_box   = crop_norm(page_img, BOX_STARTS)
        ends_box     = crop_norm(page_img, BOX_ENDS)
        way_go_box   = crop_norm(page_img, BOX_WAYgo)
        way_back_box = crop_norm(page_img, BOX_WAYback)
        meal_box     = crop_norm(page_img, BOX_MEAL)
        medic_box    = crop_norm(page_img, BOX_MEDIC)
        trial_box    = crop_norm(page_img, BOX_TRIAL)
        area_box     = crop_norm(page_img, BOX_AREA)

        def split_rows(box_img, n_rows, label):
            rows = split_rows_by_lines(box_img, debug_name=f"{label}_{seq_no}")
            if len(rows) != n_rows:
                print(f"Warning: {label} 検出行数={len(rows)}。均等分割にフォールバック。")
                rows = split_vertical(box_img, n_rows)
            return rows

        update_progress(base_progress + 30, f"ページ {seq_no}/{total_pages} の各行を分割中...")
        
        service_rows  = split_rows(service_box, NUM_ROWS, "services")
        starts_rows   = split_rows(starts_box, NUM_ROWS, "starts")
        ends_rows     = split_rows(ends_box, NUM_ROWS, "ends")
        way_go_rows   = split_rows(way_go_box, NUM_ROWS, "way_go")
        way_back_rows = split_rows(way_back_box, NUM_ROWS, "way_back")
        meal_rows     = split_rows(meal_box, NUM_ROWS, "meals")
        medic_rows    = split_rows(medic_box, NUM_ROWS, "medics")
        trial_rows    = split_rows(trial_box, NUM_ROWS, "trials")
        area_rows     = split_rows(area_box, NUM_ROWS, "areas")

        update_progress(base_progress + 40, f"ページ {seq_no}/{total_pages} の各セルをOCR解析中...")
        
        # OCR結果をまとめる
        rows = []
        for i in range(NUM_ROWS):
            day = i + 1
            
            # 進捗の細かい更新
            if i % 5 == 0:  # 5日ごとに更新
                cell_progress = base_progress + 40 + (25 * i / NUM_ROWS)
                update_progress(cell_progress, f"ページ {seq_no}/{total_pages} の{day}日目を処理中...")
            
            v_img, s_img, e_img = service_rows[i], starts_rows[i], ends_rows[i]
            wg_img, wb_img = way_go_rows[i], way_back_rows[i]
            m_img, c_img, t_img, a_img = meal_rows[i], medic_rows[i], trial_rows[i], area_rows[i]

            service_val = "" if is_blank_image(v_img, "soft") else "欠席"
            start_val = "" if is_blank_image(s_img, "soft") else ocr_time_with_fallback(s_img, model)
            end_val = "" if is_blank_image(e_img, "soft") else ocr_time_with_fallback(e_img, model)
            way_go_val = "" if is_blank_image(wg_img, "hard") else "1"
            way_back_val = "" if is_blank_image(wb_img, "hard") else "1"
            meal_val = "" if is_blank_image(m_img, "hard") else "1"
            medic_val = "" if is_blank_image(c_img, "hard") else ocr_etc_with_fallback(c_img, model)
            trial_val = "" if is_blank_image(t_img, "hard") else ocr_etc_with_fallback(t_img, model)
            area_val = "" if is_blank_image(a_img, "hard") else "1"

            rows.append({
                "Day": day,
                "Service": service_val,
                "Start": start_val,
                "End": end_val,
                "Way_go": way_go_val,
                "Way_back": way_back_val,
                "Meal": meal_val,
                "Medic": medic_val,
                "Trial": trial_val,
                "Area": area_val,
                "RecipientNumber": recipient_digits,
                "Name": name_digits,
            })

        update_progress(base_progress + 65, f"ページ {seq_no}/{total_pages} のExcelファイルを作成中...")
        
        # Excelファイル作成
        created_file = save_results_to_excel(
            rows=rows,
            recipient_digits=recipient_digits,
            name_digits=name_digits,
            output_base=output_dir,
            template_xlsx_path=os.path.join(settings.BASE_DIR, "static_files", "documents", "template.xlsx"),
            seq_no=seq_no
        )
        output_files.append(created_file)
        
        update_progress(base_progress + 70, f"ページ {seq_no}/{total_pages} 完了")

    update_progress(85, "全てのページ処理が完了しました")
    return output_files


# 従来の関数も残す（互換性のため）
def process_pdf_to_excel(pdf_path, output_dir="downloads"):
    return process_pdf_to_excel_with_progress(pdf_path, output_dir, None)


# ★修正=== 開発用: ターミナルでpython predict_from_pdf_B.pyで動かす時
if __name__ == "__main__":
    files = process_pdf_to_excel(PDF_PATH)
    print("生成したファイル:", files)